# Import necessary libraries
import gempy as gp
import gempy_viewer as gpv
import glob
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
import pandas as pd
import os
import verde as vd
from gempy_engine.core.data.centered_grid import CenteredGrid
import gemgis as gg
import pyvista as pv
from disba import PhaseDispersion,EigenFunction,PhaseSensitivity
import multiprocessing
from itertools import accumulate

from tqdm import tqdm

import time, array, random

from deap import base, creator, tools, algorithms

from CODES.modeling import create_seismic_model,calculate_parameters,calculate_parameters_from_vs
from CODES.dispersion_curves import create_velocity_model_from_profile,create_velocity_model_from_profile_vs,estimate_disp_from_velocity_model

















folder_model_name = 'MCP1'





data_path = 'OUTPUT/'+folder_model_name+'/DATA/'





figures_path = 'OUTPUT/'+folder_model_name+'/FIGURES/'








filename_feather = data_path+'observed_data.feather'

obs_data = pd.read_feather(filename_feather)





obs_data





def create_layers(min_esp, max_esp,max_total=2.0):
    '''
    This function generates a list of random layer thicknesses that sum exactly to a specified total (`max_total`). 
    Each layer thickness is randomly drawn from a uniform distribution between `min_esp` and `max_esp`, 
    ensuring that all layers meet the minimum thickness requirement (`min_esp`). 
    The final layer is adjusted so that the total thickness precisely matches `max_total`.

    Parameters:
    -----------
    min_esp : float
        Minimum thickness of an individual layer (m).
    max_esp : float
        Maximum thickness of an individual layer  (m).
    max_total : float, optional (default=2 meters)
        Maximum total thickness of all layers (m).

    Returns:
    --------
    thick_lst : list of float
        A list of layer thicknesses, each rounded to four decimal places.

    '''

    values = []
    current_sum = 0.0
    
    while True:
        remaining = round(max_total - current_sum, 1)
        
        if remaining < min_esp:
            break
        
        possible_values = [round(v, 1) for v in 
                           [min_esp + i * 0.1 for i in range(int((max_esp - min_esp) / 0.1) + 1)]
                           if v <= remaining]
        
        if not possible_values:
            break
        
        choice = random.choice(possible_values)
        values.append(choice)
        current_sum = round(current_sum + choice, 1)
        
        if current_sum == max_total:
            break
    
    return values


    return thick_lst

# ------------------------------------------------------------------

def uniform(low_thick, up_thick,low_vels,up_vels):
    """
    Generates a random velocity model with layer thicknesses (m) and Vs values (m/s).

    This function first creates a set of random layer thicknesses using 
    `create_layers()`, then assigns shear wave velocities (Vs) to each layer 
    based on a uniform distribution.

    Parameters:
    -----------
    low_thick : float
        Lower bound for layer thickness (m).
    up_thick : float
        Upper bound for layer thickness (m).
    low_vels : float
        Lower bound for Vs values (m/s).
    up_vels : float
        Upper bound for Vs values (m/s).

    Returns:
    --------
    model : list
        A list containing:
        - `thickness_lst` (list of float): Layer thicknesses.
        - `vs_lst` (list of float): Corresponding Vs values.

    Notes:
    ------
    - The first layer's Vs is sampled uniformly between `low_vels` and `up_vels`.
    - Subsequent layers have Vs values increasing with depth, where the upper 
      and lower bounds for Vs are scaled by the layer index.
    - This function is used in the DEAP framework for generating models:
      
        toolbox.register("model", uniform, lower_thick, upper_thick, lower_vs, upper_vs)
    """
    
    thickness_lst = create_layers(low_thick,up_thick)
    
    vs_lst = []
    for s in range(1,len(thickness_lst)+1):
        if s == 1:
            vs_lst.append(round(np.random.uniform(low_vels,up_vels)))
        else:
            vs_lst.append(round(np.random.uniform(low_vels*(s),up_vels*(s))))
    return [thickness_lst,vs_lst]








def inversion_objective(individual, true_disp,number_samples=100):
    """
    Objective function for inversion using DEAP.

    This function evaluates the misfit between the experimental Rayleigh wave 
    dispersion data and the theoretical dispersion curve simulated from a given 
    shear wave velocity (Vs) profile.

    Parameters:
    -----------
    individual : list or array
        Estimated Vs profile used for optimization.
    true_disp : array
        Experimental Rayleigh wave phase velocity dispersion data.
    number_samples : int, optional (default=100)
        Number of frequency samples considered for misfit calculation.

    Returns:
    --------
    misfit : float
        Misfit value computed as the root mean square error (RMSE) 
        normalized by the standard deviation of the experimental data.
    
    Notes:
    ------
    - The theoretical dispersion curve is obtained by first creating a velocity 
      model from the Vs profile and then estimating the Rayleigh wave phase velocities.
    - The misfit formula is:
    
        misfit = sqrt(sum((xdi - xci)^2 / σi^2) / nf)
        
      where:
        - xdi: Experimental Rayleigh wave phase velocity at frequency fi
        - xci: Theoretical Rayleigh wave phase velocity for the trial model at fi
        - σi: Standard deviation of the experimental data at fi
        - nf: Number of frequency samples
    - If an error occurs, the function returns a high misfit value (10).
    """
    
    try:
        simulated_velocity_model = create_velocity_model_from_profile_vs(individual)
            
        simulated_cpr = estimate_disp_from_velocity_model(simulated_velocity_model)
            
        simulated_dispersion = simulated_cpr.velocity*1000
                
        nf = number_samples 
        sigma = np.std(true_disp)
    
        misfit = np.sqrt(np.sum(((true_disp - simulated_dispersion) ** 2) / (sigma ** 2)) / nf)

   
    except:
        misfit = 10
        
    return misfit,





def statistics_save(individual):
    """
    Retrieves the fitness value of an individual.

    This function returns the fitness value(s) of the given individual, 
    which is used for tracking statistics such as mean, standard deviation, 
    minimum, and maximum fitness during the optimization process.

    Parameters:
    -----------
    individual : object
        An individual solution with an assigned fitness value.

    Returns:
    --------
    fitness_value : tuple
        The fitness value(s) of the individual.
    """
    
    return individual.fitness.values











def mutate_gaussian(ind, mutpb=0.1):
    """
    Applies Gaussian mutation to the individual's layer thicknesses and velocities,
    ensuring the structure of each sublist remains unchanged.

    Parameters:
    -----------
    individual : list
        The individual consisting of two sublists: thicknesses and velocities.
    mutpb : float, optional (default=0.1)
        Probability of mutating each value.

    Returns:
    --------
    tuple
        The mutated individual.
    """
    for i in range(len(ind)):  # Iterate over sublists (thicknesses and velocities)
        for j in range(len(ind[i])):  # Iterate over elements in sublist
            if random.random() < mutpb:  # Mutation probability check
                value = ind[i][j]
                sigma = 0.05 * abs(value)  # Standard deviation as 5% of the current value
                ind[i][j] += np.random.normal(0, sigma)  # Apply Gaussian noise
    return ind,





def crossover_two_point(ind1, ind2, cxpb=0.5):
    """
    Applies Two-Point Crossover to individuals while preserving the internal 
    structure of their sublists and respecting the shortest length between them.

    Parameters:
    -----------
    ind1 : list
        The first individual, consisting of two sublists.
    ind2 : list
        The second individual, also consisting of two sublists.
    cxpb : float, optional (default=0.5)
        The probability of performing crossover.

    Returns:
    --------
    tuple
        The two individuals after crossover.
    """
    for i in range(len(ind1)):  # Iterate over sublists (thickness and velocity)
        if random.random() < cxpb:  # Check if crossover occurs for this sublist
            # Determine the shortest length between corresponding sublists
            size = min(len(ind1[i]), len(ind2[i]))
            if size > 1:  # Perform crossover only if there are at least two elements
                # Select two crossover points
                point1, point2 = sorted(random.sample(range(size), 2))
                
                # Swap values between the two points
                for j in range(point1, point2 + 1):
                    ind1[i][j], ind2[i][j] = ind2[i][j], ind1[i][j]
                    
    return ind1, ind2














def configure_deap(estimated_disp,lower_thick,upper_thick,lower_vs,upper_vs):

    # Fitness and Individual Creation:
    creator.create("FitnessMin", base.Fitness, weights=(-1.0,))
    creator.create("Individual", list, fitness=creator.FitnessMin)

    # Toolbox Initialization:
    toolbox = base.Toolbox()

    # Using Multiple Processors 
    pool = multiprocessing.Pool()
    toolbox.register("map", pool.map)
    
    # Attribute Generator:
    toolbox.register("model", uniform, lower_thick, upper_thick, lower_vs, upper_vs)

    # Individual and Population Initialization:
    toolbox.register("individual", tools.initIterate, creator.Individual, toolbox.model)
    toolbox.register("population", tools.initRepeat, list, toolbox.individual)

    # Evaluation Function:
    toolbox.register("evaluate", inversion_objective, true_disp=estimated_disp)

    # Crossover Operation:
    toolbox.register("mate", crossover_two_point)

    # Mutation Operation:
    toolbox.register("mutate", mutate_gaussian)
    
    # Selection Strategy:
    toolbox.register("select", tools.selTournament, tournsize=3)
    
    return toolbox











VERBOSE = False


dic_inversion = []

start_time = time.time()

for dat in tqdm(obs_data.iterrows(), total=obs_data.shape[0]):
    
    # Loading the dispersion curves estimated:
    estimated_disp = dat[1]['dispersion_curve']
    
    # Starting DEAP
    toolbox = configure_deap(estimated_disp,0.3,0.5,10,500)
    
    
    population = toolbox.population(n=10000)
    
    estatistica = tools.Statistics(statistics_save)
    estatistica.register('mean',np.mean)
    estatistica.register('min',np.min)
    estatistica.register('max',np.max)
    
    hof = tools.HallOfFame(10)
    
    result, log = algorithms.eaSimple(population, toolbox, cxpb=0.5, mutpb=0.2, ngen=100,stats=estatistica,halloffame=hof,verbose=False)
    
    # -----------------------------------------------------------------------------------
    # Saving results

    dic_results = {'Vs':[hf[1] for hf in hof],'thick':[hf[0] for hf in hof],'misfit':[i['mean'] for i in log],'ngen':[i['gen'] for i in log]}
    dic_inversion.append(dic_results)
    # -----------------------------------------------------------------------------------
    # Plotting
    
    if VERBOSE:
        fig, ax = plt.subplots(figsize=(8, 6))
        add_label = True  # Variável de controle para adicionar o label apenas uma vez
        for keys in log:
            if add_label:
                ax.semilogy(keys['gen'],keys['mean'],'.k', label='value/iteration')
                add_label = False
            else:
                ax.semilogy(keys['gen'], keys['mean'], '.k')  # Sem o label
        
        ax.set_xlabel('Number of generations')
        ax.set_ylabel('Misfit')
        ax.axvline(x=len(log)-1, color='red', linestyle='--', label='Last iteration')
        ax.legend(loc='upper right')
        ax.grid(True)
        plt.tight_layout()
        ax.minorticks_on()
        ax.grid(which='major', color='gray', linestyle='-', linewidth=0.5)
        ax.grid(which='minor', color='gray', linestyle=':', linewidth=0.5, alpha=0.5)
        
        fig.savefig(figures_path+'misfit_'+str(dat[0])+'_.png', dpi=300)
    
        # ---------------------------------------------------------------------------------------------
    
        fig, (ax,ax1) = plt.subplots(1,2,figsize=(10, 10))
    
        for i in hof:

            profundidade = [0] + list(accumulate(i[0]))
            profundidade = [-j for j in profundidade]

            
            profundidade_plot = []
            velocidade_plot = []
            
            for k in range(len(i[1])):
                profundidade_plot.extend([profundidade[k], profundidade[k+1]])
                velocidade_plot.extend([i[1][k], i[1][k]])
            
            ax.step(velocidade_plot,profundidade_plot,'-b', where='post')
            ax.minorticks_on()
            ax.grid(which='major', color='gray', linestyle='-', linewidth=0.5)
            ax.grid(which='minor', color='gray', linestyle=':', linewidth=0.5, alpha=0.5)
            ax.set_ylim(-2,0)
            #ax.set_xlim(0,1500)
        
        ax.set_title('Model')

        
        ax1.set_title('Data')
        ax1.step(dat[1]['velocity_s'],dat[1]['depth'],'-b', where='post')
        ax1.minorticks_on()
        ax1.grid(which='major', color='gray', linestyle='-', linewidth=0.5)
        ax1.grid(which='minor', color='gray', linestyle=':', linewidth=0.5, alpha=0.5)
        ax1.set_ylim(-2,0)
        #ax1.set_xlim(0,1500)
        
    
        fig.savefig(figures_path+'comparison_'+str(dat[0])+'_.png', dpi=300)

        # ---------------------------------------------------------------------------------------------

end_time = time.time()
    
elapsed_time = end_time - start_time
print('Time spent (m):',elapsed_time/60)





df_inversion = pd.DataFrame.from_dict(dic_inversion)


df_inversion.to_feather(data_path+'inversion_.feather')





df_inversion = pd.read_feather(data_path+'inversion_.feather')


df_inversion.shape[0]


fig, ax = plt.subplots(figsize=(8, 6))
for dativ in df_inversion.iterrows():
    ax.semilogy(dativ[1]['ngen'], dativ[1]['misfit'], '-')  # Sem o label
        
ax.set_xlabel('Number of generations')
ax.set_ylabel('Misfit value')
ax.axvline(x=len(dativ[1]['ngen'])-1, color='red', linestyle='--', label='Last gen')
ax.legend(loc='upper right')
ax.grid(True)
plt.tight_layout()
ax.minorticks_on()
ax.grid(which='major', color='gray', linestyle='-', linewidth=0.5)
ax.grid(which='minor', color='gray', linestyle=':', linewidth=0.5, alpha=0.5)
ax.set_title('Misfit evolution of '+str(df_inversion.shape[0])+' receptors')
      
fig.savefig(figures_path+'misfit_total_.png', dpi=300)


for dativ in df_inversion.iterrows():
    fig, ax = plt.subplots(1,1,figsize=(10,10))

    thickness_mean = np.mean(dativ[1]['thick'],axis=0).tolist()
    velocity_mean = np.mean(dativ[1]['Vs'],axis=0).tolist()
    
    profundidade = [0] + list(accumulate(thickness_mean))
    profundidade = [-j for j in profundidade]
  
    profundidade_plot = []
    velocidade_plot = []
            
    for k in range(len(velocity_mean)):
        profundidade_plot.extend([profundidade[k], profundidade[k+1]])
        velocidade_plot.extend([velocity_mean[k], velocity_mean[k]])

    for w in range(len(dativ[1]['thick'])):
        depth = [-j for j in list(accumulate(dativ[1]['thick'][w]))]
        ax.step(dativ[1]['Vs'][k], depth,color='grey', where='post')    
            
    ax.step(velocidade_plot,profundidade_plot,'-b', where='post',alpha=0.5)
    ax.minorticks_on()
    ax.grid(which='major', color='gray', linestyle='-', linewidth=0.5)
    ax.grid(which='minor', color='gray', linestyle=':', linewidth=0.5, alpha=0.5)
    ax.set_ylim(-2,0)
    ax.set_title('Inversion result')


lst_receptor = np.arange(1, 50-1,5)*2


lst_receptor


depth_result_lst = []
velocity_result_lst = []
receptor_result_lst = []

depth_interval = -0.05

for dativ in df_inversion.iterrows():

    thickness_mean = np.mean(dativ[1]['thick'],axis=0).tolist()
    vels_mean = np.mean(dativ[1]['Vs'],axis=0).tolist()

    depths = [0]+[-j for j in list(accumulate(thickness_mean))]

    depths_fine = []
    vels_fine = []

    # Iterate through depth intervals
    for j in range(len(depths) - 1):
        # Create a new depth array within the interval with finer sampling
        depths_interval = np.arange(depths[j], depths[j + 1], depth_interval)

        depths_fine.extend(depths_interval)
        # Repeat the velocity value within the interval
        vels_fine.extend([vels_mean[j]] * len(depths_interval))

    receptor_result_lst.append([lst_receptor[dativ[0]]]*len(vels_fine))
    depth_result_lst.append(depths_fine)
    velocity_result_lst.append(vels_fine)


receptor_result_lst = np.array([item for sublist in receptor_result_lst for item in sublist])
depth_result_lst = np.array([item for sublist in depth_result_lst for item in sublist])
velocity_result_lst = np.array([item for sublist in velocity_result_lst for item in sublist])


# We'll test this on the air temperature data from Texas
coordinates = (receptor_result_lst, depth_result_lst)
velocitys = velocity_result_lst
region = (0,100,-2,0)


spacing = (0.1,0.1)

# Now we can set up a gridder for the decimated data
grd = vd.KNeighbors().fit(coordinates, velocitys)

print("Data region:", region)

# The 'grid' method can still make a geographic grid if we pass in a projection
# function that converts lon, lat into the easting, northing coordinates that
# we used in 'fit'. This can be any function that takes lon, lat and returns x,
# y. In our case, it'll be the 'projection' variable that we created above.
# We'll also set the names of the grid dimensions and the name the data
# variable in our grid (the default would be 'scalars', which isn't very
# informative).
grid = grd.grid(
    region=region,
    spacing=spacing,
    dims=["depth","receptor"],
    data_names="velocity",
)
print("Generated geographic grid:")
print(grid)


grid


grid.velocity.data


fig,ax = plt.subplots(1, 1, figsize=(10, 5))

im = plt.imshow(grid.velocity.data, cmap='cividis',extent=[0, 100, -2.0, 0],vmin=min(velocity_result_lst),vmax=max(velocity_result_lst),aspect=25,origin='lower')

for ix in lst_receptor:
    ax.vlines(x=ix,ymin=-2.0,ymax=0,colors='k',lw=1.0,ls='--',alpha=0.7)
    ax.scatter(x=ix,y=0.05,color='k',marker='v')

ax.hlines(y=0,xmin=0,xmax=100,colors='k',lw=2,ls='-',alpha=1)
ax.set_xlabel('Distance (m)')
ax.grid(which='major', color='gray', linestyle='-', linewidth=0.5)
ax.grid(which='minor', color='gray', linestyle=':', linewidth=0.5, alpha=0.5)
ax.set_ylabel('Depth (m)')
plt.colorbar(im, ax=ax,fraction=0.15, shrink=0.5,label='Shear-wave velocity (m/s)')
fig.savefig(figures_path+'inversion_slice_and_receptors.png')






